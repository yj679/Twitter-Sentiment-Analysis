---
title: "Twitter Text Senetiment Analysis"
author: "Yilu Jin"
date: "6/15/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

In this twitter text sentiment project, I used twitter data as my traing data and hashtags as my training labels. Eventually, I got a model that could predict the sentiment of any text. If you're interested how I did, let's have a look!

**My demo is [here](https://yilujin.shinyapps.io/sentiment/). You can type any texts you want, click 'Start Analyse', then the result will come up!**

First, let's load all the libraries we will use.
```{r message = FALSE}
library(twitteR)
library(ROAuth)
library(tm)
library(caret)
library(naivebayes)
```


## Scrape data from twitter

In order to get what people are tweeting about, we need twitter API to gather the information. Here we use two packages **twitteR** and **ROAuth**. For api key and access token etc you can use mine or simply by creating a account on twitter developers website.
```{r}
api_key <- 'sH7WuZA219JDxv89Nktt7rPzF'
api_secret <- 'WP26r06ckxBAgrm6DSo7Nkcsjn8vBnPPpigD6k173zT54uK0q1'
access_token <- '1138600074911633415-eLIy24TMVzh8sAFrgS5FM1UMsPpMqt'
access_token_secret <- '5zNjQJA1jFyTa6BNfhxZ1QH0HUnC8N2F5wWEWtOeWUIvs'

# Create Twitter Connection
setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
```

Then, we can start scraping whatever we want from twitter. I wrote a function to get twitter data by entering hashtags.
```{r}
#get twitter data
get_twitter_data <- function(hashtags){
  posDF <- NULL
  for (hashtag in hashtags){
    #twitter API limit
    Sys.sleep(0.1)
    pos <- searchTwitter(hashtag, n=5000, lang = 'en')
    pos.df <- twListToDF(pos)
    #Eliminate the retweets
    pos.df <- pos.df[which(!substr(pos.df$text,start=1,stop=2) == 'RT'),]
    pos.df$hashtag <- hashtag 
    posDF <- rbind(posDF,pos.df)
  }
  return(posDF)
}
```

In this analysis, I used positive hashtags such as **#love, #like, #beautiful, #cute, #good, #smile** to determine that the sentiment of this tweet is positive. On the other hand, **#bad, #angry, #ugly, #annoy, #hate** etc. were used to represent negative tweets. Then by the following code, we get the twitter data.

```{r eval=FALSE}
good.data <- get_twitter_data(hashtags = c('#love','#like','#beautiful','#cute','#good','#smile'))
bad.data <- get_twitter_data(hashtags = c('#bad','#angry','#ugly','#annoy','#hate','#anxious','#awful',
                                          '#boring','sad','horrible','cruel','damage','cry','depressed'))
selectc <- c('hashtag', 'id', 'text', 'created')
good.data.cut <- subset(good.data, select = selectc)
good.data.cut$label <- 'positive'
bad.data.cut <- subset(bad.data, select = selectc)
bad.data.cut$label <- 'negative'
#let the sample ratio of positive/negative = 1
good.data.cut <- good.data.cut[sample(nrow(good.data.cut),nrow(bad.data.cut)),]
twitter_data <- rbind(good.data.cut,bad.data.cut)
```

```{r include=FALSE}
load('/Users/yilujin/Desktop/learn_code/SentimentAnalysis/twitter_data.Rdata')
```

## Preprocessing

In order to get rid of the variation effect in English, I wrote a preprocessing function to apply text cleaning as the followings.
```{r}
#text processing 
preprocessing <- function(text){
  #create corpus
  text_corpus <- VCorpus(VectorSource(text))
  #remove anything except the english language and space
  NumPunct <- function(x){gsub("[^[:alpha:][:space:]]*","",x)}
  text.clean <- tm_map(text_corpus,content_transformer(NumPunct))
  #remove the links (URLs)
  removeURL <- function(x){gsub("http[^[:space:]]*","",x)}
  text.clean <- tm_map(text.clean,content_transformer(removeURL))
  text.clean <- tm_map(text.clean,content_transformer(tolower))
  text.clean <- tm_map(text.clean,removeNumbers)
  text.clean <- tm_map(text.clean,removeWords,stopwords())
  text.clean <- tm_map(text.clean,removePunctuation)
  text.clean <- tm_map(text.clean,stemDocument)
  text.clean <- tm_map(text.clean,stripWhitespace)
  text.clean <- tm_map(text.clean,removeWords,letters)
  text_processed <- as.character(text.clean[[1]])
  return(list(text.clean, text_processed))
}
```

Let's test if it works by entering a simple sentences, say 'I drove all the ways to my grandma's home'. 
```{r}
preprocessing("I drove all the ways to my grandma's home")[[2]]
```
```{r}
preprocessing("I like to walk my dog on sunny days.")[[2]]
```
```{r}
preprocessing("Seriously!! The man opposite has his phone up as loud as possible!!")[[2]]
```

It works! And we use this function to get the twitter data cleaned.

```{r}
tweets.clean <- preprocessing(twitter_data$text)
```

## Remove Sparse Terms 

Here we try different ratios to exclude the sparse terms. I wrote a function to test the performence of each ratio using cross validation and Naive Bayse classifier. Then we see which one performs the best. 

```{r}
train_with_r_sparse <- function(r_range){
  i <- 0
  accuracy <- c()
  possible_sparse <- c()
  tweet_dtm <- DocumentTermMatrix(tweets.clean[[1]])
  for (r in r_range) {
    i = i+1
    S_DTM <- removeSparseTerms(tweet_dtm,r)
    tweetsS <- as.data.frame(as.matrix(S_DTM))
    tweetsS$label <- twitter_data$label
    set.seed(1234)
    ind <- createDataPartition(tweetsS$label, p=0.8,list = FALSE)
    train_data <- tweetsS[ind,]
    test_data <- tweetsS[-ind,]
    model <- naive_bayes(label ~ ., data = train_data)
    p1 <- predict(model, test_data)
    tab1 <- table(p1, test_data$label)
    accuracy[i] <- sum(diag(tab1)) / sum(tab1)
    possible_sparse[i] <- r
  }
  return(data.frame(possible_sparse,accuracy))
}
```

```{r message=FALSE, warning=FALSE}
r_range <- seq(0.90,0.99, by=0.01)
sparse_accuracies <- train_with_r_sparse(r_range)
plot(sparse_accuracies) 
```

From the plot, 0.987 is the best.
```{r message=FALSE, warning=FALSE}
r_range <- seq(0.980,0.999, by=0.001)
sparse_accuracies <- train_with_r_sparse(r_range)
plot(sparse_accuracies) # 0.987 is the best
```

## Train Actual Model

Text documents needs to be splitted into words to be analysed. First we transfer texts into words vectors, then remove sparse terms, make a dataframe followed by adding labels to the 
df.
```{r}
#split text documents into words
tweet_dtm <- DocumentTermMatrix(tweets.clean[[1]])
S_DTM <- removeSparseTerms(tweet_dtm,0.987)
tweetsS <- as.data.frame(as.matrix(S_DTM))
tweetsS$label <- twitter_data$label
```

Split the data into train set and test set. Apply naive bayes classifier to obtain a model to predict any texts given. Save the model for later using (load the model to build shiny web app).

```{r}
#partition into train and test
set.seed(1234)
ind <- createDataPartition(tweetsS$label, p=0.8,list = FALSE)
train_data <- tweetsS[ind,]
test_data <- tweetsS[-ind,]
# model <- naive_bayes(label ~ ., data = train_data, usekernel = T)
model <- naive_bayes(label ~ ., data = train_data)
save(model, file = 'model.rda')
```

## Prediction

I wrote a predict function to analyse any texts. Now we are ready to analyze!

```{r}
#analyze tweets sentiment 
predict_new <- function(sentence){
  sentence <- preprocessing(sentence)
  feature <- as.data.frame(as.matrix(DocumentTermMatrix(sentence[[1]])))
  pred <- predict(model, feature)
  return(cat(substr(pred, start = 1, stop = 8)))
}
```

```{r message=FALSE, warning=FALSE}
# Analyze a sentence 
predict_new('I feel really anxious!')
```

We can also analyse a certain topic on twitter by using this function and previous codes. We simply type the hashtags we are concerned, then we will get the result from this `predict_new_hashtag` function.

```{r}
predict_new_hashtag <- function(hashtag){
  hash_data <- get_twitter_data(hashtag)
  sentence <- preprocessing(hash_data$text)
  feature <- as.data.frame(as.matrix(DocumentTermMatrix(sentence[[1]])))
  pred <- predict(model, feature)
  ratio <- length(which(pred == 'positive')) / length(pred)
  percent <- round(ratio * 100, digits = 2)
  return(cat(percent))
}
```

```{r message=FALSE, warning=FALSE}
# Analyze a certain hashtag in twitter
sunset_predict <- predict_new_hashtag('#sunset')
```
We see that 31.36% of all the samples with #sunset are positive.

